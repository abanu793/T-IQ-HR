{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babc5890",
   "metadata": {},
   "source": [
    "## 04_Performance_Model.ipynb\n",
    "\n",
    "**Purpose:**  \n",
    "Train and evaluate employee performance prediction model.\n",
    "\n",
    "**Input:**  \n",
    "- `data/raw/hrms_synth_summary.csv`\n",
    "\n",
    "**Output:**  \n",
    "- Model artifacts saved to:\n",
    "  - `notebooks/models/preprocessor_perf.pkl`\n",
    "  - `notebooks/models/performance_model.pkl`\n",
    "\n",
    "**Notes:**  \n",
    "- Focuses on performance-related KPIs from HRMS data.  \n",
    "- Output models are used during performance inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a679ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589cf9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>department</th>\n",
       "      <th>job_role</th>\n",
       "      <th>location</th>\n",
       "      <th>current_salary</th>\n",
       "      <th>satisfaction_score</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>num_skills</th>\n",
       "      <th>years_at_company</th>\n",
       "      <th>trainings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMP000001</td>\n",
       "      <td>Vikram Singh</td>\n",
       "      <td>HR</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>4544478</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMP000002</td>\n",
       "      <td>Karan Patel</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai, India</td>\n",
       "      <td>5180268</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.93</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMP000003</td>\n",
       "      <td>Vikram Malhotra</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>Chennai, India</td>\n",
       "      <td>2589268</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMP000004</td>\n",
       "      <td>Siddharth Khan</td>\n",
       "      <td>HR</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>1321856</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP000005</td>\n",
       "      <td>Priya Nair</td>\n",
       "      <td>Legal</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>4371479</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id             name department                  job_role  \\\n",
       "0   EMP000001     Vikram Singh         HR            Data Scientist   \n",
       "1   EMP000002      Karan Patel  Marketing            Data Scientist   \n",
       "2   EMP000003  Vikram Malhotra  Marketing  Senior Software Engineer   \n",
       "3   EMP000004   Siddharth Khan         HR               ML Engineer   \n",
       "4   EMP000005       Priya Nair      Legal               ML Engineer   \n",
       "\n",
       "           location  current_salary  satisfaction_score  engagement_score  \\\n",
       "0     New York, USA         4544478                0.78              0.80   \n",
       "1    Chennai, India         5180268                0.71              0.93   \n",
       "2    Chennai, India         2589268                0.81              0.56   \n",
       "3  Bengaluru, India         1321856                0.43              0.95   \n",
       "4            Remote         4371479                0.41              0.70   \n",
       "\n",
       "   num_skills  years_at_company  trainings_count  \n",
       "0           7                12                0  \n",
       "1           8                 7                4  \n",
       "2           6                 3                3  \n",
       "3           7                15                3  \n",
       "4           4                 7                2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = r\"C:\\Users\\abanu\\Documents\\t_iq_hr\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    BASE_PATH + r\"\\data\\raw\\hrms_synth_summary.csv\"\n",
    ")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb016743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "performance_score\n",
       "1    2009\n",
       "2    1992\n",
       "3    2028\n",
       "4    1990\n",
       "5    1981\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "df[\"performance_score\"] = (\n",
    "    0.4 * df[\"satisfaction_score\"] +\n",
    "    0.4 * df[\"engagement_score\"] +\n",
    "    0.2 * (df[\"num_skills\"] / df[\"num_skills\"].max())\n",
    ")\n",
    "\n",
    "df[\"performance_score\"] = pd.qcut(\n",
    "    df[\"performance_score\"],\n",
    "    q=5,\n",
    "    labels=[1, 2, 3, 4, 5]\n",
    ").astype(int)\n",
    "\n",
    "df[\"performance_score\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cbbf11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 9), (2000, 9))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    'department',\n",
    "    'job_role',\n",
    "    'location',\n",
    "    'current_salary',\n",
    "    'satisfaction_score',\n",
    "    'engagement_score',\n",
    "    'num_skills',\n",
    "    'years_at_company',\n",
    "    'trainings_count'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['performance_score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae58b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\n",
    "    'current_salary',\n",
    "    'satisfaction_score',\n",
    "    'engagement_score',\n",
    "    'num_skills',\n",
    "    'years_at_company',\n",
    "    'trainings_count'\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'department',\n",
    "    'job_role',\n",
    "    'location'\n",
    "]\n",
    "\n",
    "preprocessor_perf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "310a9d3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got [1 2 3 4 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m performance_pipeline = Pipeline([\n\u001b[32m      2\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m, preprocessor_perf),\n\u001b[32m      3\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m'\u001b[39m, XGBClassifier(\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     ))\n\u001b[32m      9\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mperformance_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Performance model trained\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    472\u001b[39m         last_step_params = routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\xgboost\\sklearn.py:1761\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1756\u001b[39m     expected_classes = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1757\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1758\u001b[39m     classes.shape != expected_classes.shape\n\u001b[32m   1759\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes == expected_classes).all()\n\u001b[32m   1760\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1761\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1762\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1763\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1764\u001b[39m     )\n\u001b[32m   1766\u001b[39m params = \u001b[38;5;28mself\u001b[39m.get_xgb_params()\n\u001b[32m   1768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n",
      "\u001b[31mValueError\u001b[39m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got [1 2 3 4 5]"
     ]
    }
   ],
   "source": [
    "performance_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_perf),\n",
    "    ('classifier', XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=5,\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "performance_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Performance model trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff23014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['performance_score'] = df['performance_score'] - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a37bba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'department',\n",
    "    'job_role',\n",
    "    'location',\n",
    "    'current_salary',\n",
    "    'satisfaction_score',\n",
    "    'engagement_score',\n",
    "    'num_skills',\n",
    "    'years_at_company',\n",
    "    'trainings_count'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['performance_score']   # now 0–4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f7c8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b155714d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Performance model trained\n"
     ]
    }
   ],
   "source": [
    "performance_pipeline.fit(X_train, y_train)\n",
    "print(\"✅ Performance model trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "060c746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       402\n",
      "           1       0.95      0.95      0.95       398\n",
      "           2       0.95      0.94      0.95       406\n",
      "           3       0.93      0.94      0.93       398\n",
      "           4       0.97      0.96      0.97       396\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.95      0.95      0.95      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_pred = performance_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b022b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ performance_model.pkl saved\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"notebooks/models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(\"notebooks/models/performance_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(performance_pipeline, f)\n",
    "\n",
    "print(\"✅ performance_model.pkl saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56c98ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abanu\\Documents\\t_iq_hr\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e7965b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_Performance</th>\n",
       "      <th>Predicted_Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual_Performance  Predicted_Performance\n",
       "0                   1                      1\n",
       "1                   2                      2\n",
       "2                   3                      3\n",
       "3                   5                      5\n",
       "4                   1                      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = X_test.iloc[:5]\n",
    "\n",
    "pred = performance_pipeline.predict(sample) + 1\n",
    "actual = y_test.iloc[:5] + 1\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Actual_Performance\": actual.values,\n",
    "    \"Predicted_Performance\": pred\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb87ab5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>department</th>\n",
       "      <th>job_role</th>\n",
       "      <th>location</th>\n",
       "      <th>current_salary</th>\n",
       "      <th>satisfaction_score</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>num_skills</th>\n",
       "      <th>years_at_company</th>\n",
       "      <th>trainings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMP000001</td>\n",
       "      <td>Vikram Singh</td>\n",
       "      <td>HR</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>4544478</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMP000002</td>\n",
       "      <td>Karan Patel</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai, India</td>\n",
       "      <td>5180268</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.93</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMP000003</td>\n",
       "      <td>Vikram Malhotra</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>Chennai, India</td>\n",
       "      <td>2589268</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMP000004</td>\n",
       "      <td>Siddharth Khan</td>\n",
       "      <td>HR</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>1321856</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP000005</td>\n",
       "      <td>Priya Nair</td>\n",
       "      <td>Legal</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>4371479</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id             name department                  job_role  \\\n",
       "0   EMP000001     Vikram Singh         HR            Data Scientist   \n",
       "1   EMP000002      Karan Patel  Marketing            Data Scientist   \n",
       "2   EMP000003  Vikram Malhotra  Marketing  Senior Software Engineer   \n",
       "3   EMP000004   Siddharth Khan         HR               ML Engineer   \n",
       "4   EMP000005       Priya Nair      Legal               ML Engineer   \n",
       "\n",
       "           location  current_salary  satisfaction_score  engagement_score  \\\n",
       "0     New York, USA         4544478                0.78              0.80   \n",
       "1    Chennai, India         5180268                0.71              0.93   \n",
       "2    Chennai, India         2589268                0.81              0.56   \n",
       "3  Bengaluru, India         1321856                0.43              0.95   \n",
       "4            Remote         4371479                0.41              0.70   \n",
       "\n",
       "   num_skills  years_at_company  trainings_count  \n",
       "0           7                12                0  \n",
       "1           8                 7                4  \n",
       "2           6                 3                3  \n",
       "3           7                15                3  \n",
       "4           4                 7                2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned HRMS data\n",
    "hrms = pd.read_csv(r\"C:\\Users\\abanu\\Documents\\t_iq_hr\\data\\processed\\HRMS_cleaned.csv\")\n",
    "hrms.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a203a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>performance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMP000001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMP000002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMP000003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMP000004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP000005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id  performance_score\n",
       "0   EMP000001                  1\n",
       "1   EMP000002                  1\n",
       "2   EMP000003                  1\n",
       "3   EMP000004                  1\n",
       "4   EMP000005                  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# If you want a synthetic score, you can use weighted combination\n",
    "hrms['performance_score'] = (\n",
    "    0.4 * hrms['satisfaction_score'] +\n",
    "    0.4 * hrms['engagement_score'] +\n",
    "    0.2 * (hrms['trainings_count'] / (hrms['trainings_count'].max() + 1))\n",
    ").round().astype(int)\n",
    "\n",
    "# Make sure values are between 1 and 5\n",
    "hrms['performance_score'] = hrms['performance_score'].clip(1,5)\n",
    "\n",
    "hrms[['employee_id','performance_score']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e42ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HRMS_with_performance.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save HRMS with performance scores\n",
    "hrms.to_csv(r\"C:\\Users\\abanu\\Documents\\t_iq_hr\\data\\processed\\HRMS_with_performance.csv\", index=False)\n",
    "print(\"✅ HRMS_with_performance.csv saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4de810f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0], got [1]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     28\u001b[39m performance_pipeline = Pipeline([\n\u001b[32m     29\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m, preprocessor_perf),\n\u001b[32m     30\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m'\u001b[39m, XGBClassifier(objective=\u001b[33m'\u001b[39m\u001b[33mmulti:softmax\u001b[39m\u001b[33m'\u001b[39m, num_class=\u001b[32m5\u001b[39m, random_state=\u001b[32m42\u001b[39m))\n\u001b[32m     31\u001b[39m ])\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mperformance_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Performance model trained\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Save preprocessor & model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    472\u001b[39m         last_step_params = routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\xgboost\\sklearn.py:1761\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1756\u001b[39m     expected_classes = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1757\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1758\u001b[39m     classes.shape != expected_classes.shape\n\u001b[32m   1759\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes == expected_classes).all()\n\u001b[32m   1760\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1761\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1762\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1763\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1764\u001b[39m     )\n\u001b[32m   1766\u001b[39m params = \u001b[38;5;28mself\u001b[39m.get_xgb_params()\n\u001b[32m   1768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n",
      "\u001b[31mValueError\u001b[39m: Invalid classes inferred from unique values of `y`.  Expected: [0], got [1]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "# Features & target\n",
    "features = ['department', 'job_role', 'location', 'current_salary',\n",
    "            'satisfaction_score', 'engagement_score', 'num_skills', \n",
    "            'years_at_company', 'trainings_count']\n",
    "X = hrms[features]\n",
    "y = hrms['performance_score']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessor\n",
    "categorical_features = ['department','job_role','location']\n",
    "numeric_features = ['current_salary','satisfaction_score','engagement_score','num_skills','years_at_company','trainings_count']\n",
    "\n",
    "preprocessor_perf = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# Performance model pipeline\n",
    "performance_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_perf),\n",
    "    ('classifier', XGBClassifier(objective='multi:softmax', num_class=5, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "performance_pipeline.fit(X_train, y_train)\n",
    "print(\"✅ Performance model trained\")\n",
    "\n",
    "# Save preprocessor & model\n",
    "with open(r\"C:\\Users\\abanu\\Documents\\t_iq_hr\\notebooks\\models\\preprocessor_perf.pkl\", 'wb') as f:\n",
    "    pickle.dump(preprocessor_perf, f)\n",
    "\n",
    "with open(r\"C:\\Users\\abanu\\Documents\\t_iq_hr\\notebooks\\models\\performance_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(performance_pipeline, f)\n",
    "\n",
    "print(\"✅ Preprocessor and performance model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0ceed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance_score\n",
      "3    5810\n",
      "4    2263\n",
      "2    1899\n",
      "5      15\n",
      "1      13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make performance_score values more spread out\n",
    "hrms['performance_score'] = (\n",
    "    0.4 * hrms['satisfaction_score'] +\n",
    "    0.4 * hrms['engagement_score'] +\n",
    "    0.2 * (hrms['trainings_count'] / (hrms['trainings_count'].max()+1))\n",
    ") * 5  # scale up\n",
    "\n",
    "# Round and clip to 1-5\n",
    "hrms['performance_score'] = hrms['performance_score'].round().clip(1,5).astype(int)\n",
    "\n",
    "# Check distribution\n",
    "print(hrms['performance_score'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014219c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['department', 'job_role', 'location', 'current_salary',\n",
    "            'satisfaction_score', 'engagement_score', 'num_skills',\n",
    "            'years_at_company', 'trainings_count']\n",
    "\n",
    "X = hrms[features]\n",
    "y = hrms['performance_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f27638b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8000, 9)\n",
      "X_test shape: (2000, 9)\n",
      "y_train distribution:\n",
      " performance_score\n",
      "3    4648\n",
      "4    1811\n",
      "2    1519\n",
      "5      12\n",
      "1      10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train distribution:\\n\", y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f39d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "categorical_cols = ['department', 'job_role', 'location']\n",
    "numerical_cols = ['current_salary', 'satisfaction_score', 'engagement_score', \n",
    "                  'num_skills', 'years_at_company', 'trainings_count']\n",
    "\n",
    "preprocessor_perf = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861aed19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got [1 2 3 4 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m      3\u001b[39m performance_pipeline = Pipeline([\n\u001b[32m      4\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m, preprocessor_perf),\n\u001b[32m      5\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m'\u001b[39m, XGBClassifier(\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     ))\n\u001b[32m     11\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mperformance_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Performance model trained\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    472\u001b[39m         last_step_params = routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\xgboost\\sklearn.py:1761\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1756\u001b[39m     expected_classes = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1757\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1758\u001b[39m     classes.shape != expected_classes.shape\n\u001b[32m   1759\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes == expected_classes).all()\n\u001b[32m   1760\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1761\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1762\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1763\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1764\u001b[39m     )\n\u001b[32m   1766\u001b[39m params = \u001b[38;5;28mself\u001b[39m.get_xgb_params()\n\u001b[32m   1768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n",
      "\u001b[31mValueError\u001b[39m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got [1 2 3 4 5]"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "performance_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_perf),\n",
    "    ('classifier', XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=5,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False\n",
    "    ))\n",
    "])\n",
    "\n",
    "performance_pipeline.fit(X_train, y_train)\n",
    "print(\"✅ Performance model trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568d62c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abanu\\Documents\\t_iq_hr\\env\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:17:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# Shift labels to 0-based\n",
    "y_train_zero = y_train - 1\n",
    "y_test_zero = y_test - 1\n",
    "\n",
    "performance_pipeline.fit(X_train, y_train_zero)\n",
    "y_pred_zero = performance_pipeline.predict(X_test)\n",
    "y_pred = y_pred_zero + 1  # Shift predictions back to original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "543d1cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.96      0.98      0.97       380\n",
      "           3       0.99      0.97      0.98      1162\n",
      "           4       0.96      0.98      0.97       452\n",
      "           5       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.88      0.85      0.87      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c9859c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a472785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>department</th>\n",
       "      <th>job_role</th>\n",
       "      <th>location</th>\n",
       "      <th>current_salary</th>\n",
       "      <th>satisfaction_score</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>num_skills</th>\n",
       "      <th>years_at_company</th>\n",
       "      <th>trainings_count</th>\n",
       "      <th>performance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMP000001</td>\n",
       "      <td>Vikram Singh</td>\n",
       "      <td>HR</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>4544478</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMP000002</td>\n",
       "      <td>Karan Patel</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai, India</td>\n",
       "      <td>5180268</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.93</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMP000003</td>\n",
       "      <td>Vikram Malhotra</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>Chennai, India</td>\n",
       "      <td>2589268</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMP000004</td>\n",
       "      <td>Siddharth Khan</td>\n",
       "      <td>HR</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>1321856</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP000005</td>\n",
       "      <td>Priya Nair</td>\n",
       "      <td>Legal</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>4371479</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id             name department                  job_role  \\\n",
       "0   EMP000001     Vikram Singh         HR            Data Scientist   \n",
       "1   EMP000002      Karan Patel  Marketing            Data Scientist   \n",
       "2   EMP000003  Vikram Malhotra  Marketing  Senior Software Engineer   \n",
       "3   EMP000004   Siddharth Khan         HR               ML Engineer   \n",
       "4   EMP000005       Priya Nair      Legal               ML Engineer   \n",
       "\n",
       "           location  current_salary  satisfaction_score  engagement_score  \\\n",
       "0     New York, USA         4544478                0.78              0.80   \n",
       "1    Chennai, India         5180268                0.71              0.93   \n",
       "2    Chennai, India         2589268                0.81              0.56   \n",
       "3  Bengaluru, India         1321856                0.43              0.95   \n",
       "4            Remote         4371479                0.41              0.70   \n",
       "\n",
       "   num_skills  years_at_company  trainings_count  performance_score  \n",
       "0           7                12                0                  1  \n",
       "1           8                 7                4                  1  \n",
       "2           6                 3                3                  1  \n",
       "3           7                15                3                  1  \n",
       "4           4                 7                2                  1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\abanu\\Documents\\t_iq_hr\\data\\processed\\HRMS_with_performance.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a6fe74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "performance_score_enc\n",
       "0    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure integer type\n",
    "df['performance_score'] = df['performance_score'].astype(int)\n",
    "\n",
    "# Convert 1–5 → 0–4\n",
    "df['performance_score_enc'] = df['performance_score'] - 1\n",
    "\n",
    "df['performance_score_enc'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "054fcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['performance_score', 'performance_score_enc'])\n",
    "y = df['performance_score_enc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cead769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8000, 11)\n",
      "Test : (2000, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Test :\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25101354",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    'current_salary',\n",
    "    'satisfaction_score',\n",
    "    'engagement_score',\n",
    "    'num_skills',\n",
    "    'years_at_company',\n",
    "    'trainings_count'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'department',\n",
    "    'job_role',\n",
    "    'location'\n",
    "]\n",
    "\n",
    "preprocessor_perf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c818953",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_perf),\n",
    "    ('classifier', XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=5,\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='mlogloss'\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6250c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Performance model trained\n"
     ]
    }
   ],
   "source": [
    "performance_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Performance model trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56839286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = performance_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ba77746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ preprocessor_perf.pkl and performance_model.pkl saved\n"
     ]
    }
   ],
   "source": [
    "model_path = r\"C:\\\\Users\\\\abanu\\\\Documents\\\\t_iq_hr\\\\notebooks\\\\models\"\n",
    "\n",
    "# Save preprocessor\n",
    "with open(f\"{model_path}\\\\preprocessor_perf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preprocessor_perf, f)\n",
    "\n",
    "# Save full pipeline\n",
    "with open(f\"{model_path}\\\\performance_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(performance_pipeline, f)\n",
    "\n",
    "print(\"✅ preprocessor_perf.pkl and performance_model.pkl saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e419bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
